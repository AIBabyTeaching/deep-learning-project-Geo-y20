{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Image....\n",
      "Image Loaded\n",
      "Training In Progress.....\n",
      "Total Error = 0.487795\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mg:\\Term 6\\Deep Learning\\Optical-Character-Recognition-BackPropagation\\OCR.ipynb Cell 1\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Term%206/Deep%20Learning/Optical-Character-Recognition-BackPropagation/OCR.ipynb#W0sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTraining In Progress.....\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Term%206/Deep%20Learning/Optical-Character-Recognition-BackPropagation/OCR.ipynb#W0sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m Wi_h, Wh_o, Bh , Bo \u001b[39m=\u001b[39m cR\u001b[39m.\u001b[39minitializeWeights(width,height,numberOfHiddenNeurons)                     \u001b[39m# initialize weights\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/g%3A/Term%206/Deep%20Learning/Optical-Character-Recognition-BackPropagation/OCR.ipynb#W0sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m Wi_h, Wh_o, Bh , Bo \u001b[39m=\u001b[39m cR\u001b[39m.\u001b[39;49mtrainNet(Wi_h, Wh_o, Bh , Bo,height,width,numberOfTrainingSamples,learningRate,momentum,targetError) \u001b[39m# train net\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Term%206/Deep%20Learning/Optical-Character-Recognition-BackPropagation/OCR.ipynb#W0sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mNeural Net Trained\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Term%206/Deep%20Learning/Optical-Character-Recognition-BackPropagation/OCR.ipynb#W0sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m######################################################################################\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Term%206/Deep%20Learning/Optical-Character-Recognition-BackPropagation/OCR.ipynb#W0sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m##################### Recognize Paragraphs,Lines,Words and Characters#################\u001b[39;00m\n",
      "File \u001b[1;32mg:\\Term 6\\Deep Learning\\Optical-Character-Recognition-BackPropagation\\CharacterRecognition.py:153\u001b[0m, in \u001b[0;36mtrainNet\u001b[1;34m(Wi_h, Wh_o, Bh, Bo, height, width, numberOfTrainingSamples, learningRate, momentum, targetError)\u001b[0m\n\u001b[0;32m    151\u001b[0m         outputOfOutNeurons, outputOfHiddenNeurons \u001b[39m=\u001b[39m feedForward(normalized, Wi_h, Wh_o, Bh, Bo) \u001b[39m# feed forward\u001b[39;00m\n\u001b[0;32m    152\u001b[0m         outputError         \u001b[39m=\u001b[39m calculateErrorAtOutput(outputOfOutNeurons, targetOutput)          \u001b[39m# calculate error at output neurons\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m         Wi_h, Wh_o          \u001b[39m=\u001b[39m backPropagate(Wi_h, Wh_o, Bh, Bo, normalized, outputError, outputOfOutNeurons, outputOfHiddenNeurons, learningRate,momentum) \u001b[39m# backpropage and adjust weights\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[39m#-----------------------Calculate the mean squared error\u001b[39;00m\n\u001b[0;32m    156\u001b[0m totalError \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mg:\\Term 6\\Deep Learning\\Optical-Character-Recognition-BackPropagation\\CharacterRecognition.py:119\u001b[0m, in \u001b[0;36mbackPropagate\u001b[1;34m(Wi_h, Wh_o, Bh, Bo, normalized, outputError, outputOfOutNeurons, outputOfHiddenNeurons, learningRate, momentum)\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m (\u001b[39m0\u001b[39m,width):\n\u001b[0;32m    117\u001b[0m             \u001b[39m# delta Total Error with respect to weight to be adjusted. this weight is connecting input to current hidden layer\u001b[39;00m\n\u001b[0;32m    118\u001b[0m             deltaTotalError_inputTohiddenNeuronWeight \u001b[39m=\u001b[39m deltaTotalError_hiddenNeuron \u001b[39m*\u001b[39m outputOfHiddenNeurons[hiddenNeuron] \u001b[39m*\u001b[39m(\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m outputOfHiddenNeurons[hiddenNeuron]) \u001b[39m*\u001b[39m normalized[i,j]\n\u001b[1;32m--> 119\u001b[0m             Wi_h[hiddenNeuron,i,j] \u001b[39m=\u001b[39m (momentum \u001b[39m*\u001b[39m Wi_h[hiddenNeuron,i,j]) \u001b[39m-\u001b[39m (learningRate \u001b[39m*\u001b[39m deltaTotalError_inputTohiddenNeuronWeight)\n\u001b[0;32m    121\u001b[0m \u001b[39mreturn\u001b[39;00m Wi_h, Wh_o\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import LineExtraction as lN\n",
    "import CharacterRecognition as cR\n",
    "import CropAndNormalize as cAn\n",
    "from PIL import Image as im\n",
    "\n",
    "#####PARAMETERS\n",
    "learningRate = 0.5; momentum = 1; targetError = 0.0035 ;numberOfHiddenNeurons = 80\n",
    "width=18; height = 16 ;\n",
    "numberOfTrainingSamples = 4;\n",
    "documentLocation       = 'paragraphs\\\\test.png'\n",
    "\n",
    "######################################################################################\n",
    "############################## Prepare Image #########################################\n",
    "print('Loading Image....')\n",
    "imageIn                                                 = im.open('%s' %documentLocation)          # open image\n",
    "imageInBW                                               = cAn.convertToBW(imageIn)                 # 0-> black , 1-> white\n",
    "imageInBW                                               = cAn.toggleOnesAndZeros(imageInBW)        # 1-> black , 0 -> white\n",
    "imageIn.show()\n",
    "print('Image Loaded')\n",
    "######################################################################################\n",
    "############################## Initialize And Train Network ##########################\n",
    "\n",
    "print('Training In Progress.....')\n",
    "Wi_h, Wh_o, Bh , Bo = cR.initializeWeights(width,height,numberOfHiddenNeurons)                     # initialize weights\n",
    "Wi_h, Wh_o, Bh , Bo = cR.trainNet(Wi_h, Wh_o, Bh , Bo,height,width,numberOfTrainingSamples,learningRate,momentum,targetError) # train net\n",
    "print('Neural Net Trained')\n",
    "\n",
    "\n",
    "######################################################################################\n",
    "##################### Recognize Paragraphs,Lines,Words and Characters#################\n",
    "\n",
    "[croppedLinesList,numberOfLines,topOfLines,bottomOfLines]  = lN.cropLines(imageInBW)              # Extract Lines\n",
    "locationOfNewLines                                         = lN.cropParagraphs(numberOfLines,topOfLines,bottomOfLines) # get location of new lines\n",
    "numberOfNewLines                                           = len(locationOfNewLines)\n",
    "linesContents                                              = []\n",
    "\n",
    "# Loop for all Lines\n",
    "for line in range(0,numberOfLines):\n",
    "    [croppedCharactersList,numberOfCharacters,leftOfCharacters,rightOfCharacters]= lN.cropCharacters(croppedLinesList[line],numberOfLines)# Characters from Line\n",
    "    recognizedCharacterlist        = []\n",
    "    # Loop for all characters in lines\n",
    "    for character in range(0,numberOfCharacters):\n",
    "        inputCroppedBW          = cAn.crop(croppedCharactersList[character])                    # crop image to get the character only\n",
    "        inputNormalized         = cAn.normalize(inputCroppedBW,width,height)                    # normalize to neural net size\n",
    "               \n",
    "        output                  = cR.recognizeCharacter(inputNormalized,Wi_h, Wh_o, Bh, Bo)     # normalized image is sent to recognition\n",
    "        recognizedCharacterlist.append(output)                                                  # save characters found in line\n",
    "\n",
    "        print('character number %d is %s' %(character,output))\n",
    "       \n",
    "    #crop Words from Line\n",
    "    [words,numberOfWords] = lN.cropWords(recognizedCharacterlist,leftOfCharacters,rightOfCharacters) # form words from characters found in line\n",
    "    linesContents.append(words)                                                                 # save words\n",
    "     \n",
    "print(linesContents)\n",
    "\n",
    "#######################################################################################\n",
    "################################# STORE TO A TXT ######################################\n",
    "\n",
    "fileName = open('OCR_OUTPUT.txt','w')\n",
    "newLinesIndex = 0\n",
    "for line in range(0,len(linesContents)):\n",
    "    if line > 0:                                    # No NewLine if its the first line\n",
    "        fileName.write('\\n')\n",
    "    for word in range(0,len(linesContents[line])):  # writing words\n",
    "        fileName.write(linesContents[line][word])\n",
    "        fileName.write(' ')\n",
    "    \n",
    "    if line == locationOfNewLines[newLinesIndex]:   # paragraphs spacing\n",
    "        fileName.write('\\n')\n",
    "        if numberOfNewLines-1 > newLinesIndex:\n",
    "            newLinesIndex += 1\n",
    "fileName.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
